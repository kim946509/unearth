"""
í¬ë¡¤ë§ ë§¤ë‹ˆì € - ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì¡°ìœ¨
"""
import logging
from datetime import date
from typing import Dict, List, Any, Optional

from crawling.repository.song_service import SongService
from crawling.utils.batch_crawling_logger import BatchCrawlingLogger
from crawling.repository.failure_service import FailureService
from crawling.repository.db_writer import save_all_platforms_for_songs

# í”Œë«í¼ ì „ëµë“¤ import (ìƒˆë¡œìš´ êµ¬ì¡°)
from crawling.service.genie import GenieCrawlingStrategy
from crawling.service.youtube import YouTubeCrawlingStrategy
from crawling.service.youtube_music import YouTubeMusicCrawlingStrategy
from crawling.service.melon import MelonCrawlingStrategy

# YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ import
from crawling.service.youtube.youtube_api_service import update_youtube_viewcounts_for_period

logger = logging.getLogger(__name__)


def songinfo_to_dict(song):
    return {
        'song_id': song.id,
        'title_ko': song.title_ko,
        'title_en': getattr(song, 'title_en', ''),
        'artist_ko': song.artist_ko,
        'artist_en': getattr(song, 'artist_en', ''),
        'youtube_url': getattr(song, 'youtube_url', ''),
        'melon_song_id': getattr(song, 'melon_song_id', ''),
        # í•„ìš”ì— ë”°ë¼ ì¶”ê°€ í•„ë“œ ì‘ì„±
    }

class CrawlingManager:
    """í¬ë¡¤ë§ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨í•˜ëŠ” ë§¤ë‹ˆì € í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.log_writer = BatchCrawlingLogger()
        # ê° í”Œë«í¼ ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.platform_strategies = {
            'genie': GenieCrawlingStrategy(),
            'youtube': YouTubeCrawlingStrategy(),
            'youtube_music': YouTubeMusicCrawlingStrategy(),
            'melon': MelonCrawlingStrategy()
        }
    
    def run_full_crawling(self, target_date: Optional[date] = None) -> Dict[str, Any]:
        """
        ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            target_date: í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œ. Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
            
        Returns:
            í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½
        """
        try:
            logger.info("ğŸš€ ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
            
            # 1ë‹¨ê³„: í¬ë¡¤ë§ ëŒ€ìƒ ë…¸ë˜ ì¡°íšŒ
            active_songs = SongService.get_active_songs(target_date)
            
            if not active_songs:
                logger.warning("âš ï¸ í¬ë¡¤ë§ ëŒ€ìƒ ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {'status': 'no_songs', 'message': 'í¬ë¡¤ë§ ëŒ€ìƒ ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.'}
            
            logger.info(f"ğŸ“‹ í¬ë¡¤ë§ ëŒ€ìƒ: {len(active_songs)}ê°œ ê³¡")
            
            # ë¡œê·¸ ë¼ì´í„° ì‹œì‘
            self.log_writer.start_crawling(target_date or date.today(), len(active_songs))
            
            # 2ë‹¨ê³„: í”Œë«í¼ë³„ í¬ë¡¤ë§ ì‹¤í–‰
            crawling_results = {}
            
            for platform_name, strategy in self.platform_strategies.items():
                platform_songs = SongService.get_songs_by_platform(active_songs, platform_name)
                # SongInfo ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                platform_songs_dict = [songinfo_to_dict(song) for song in platform_songs]
                
                if platform_songs_dict:
                    logger.info(f"ğŸ¯ {platform_name} í¬ë¡¤ë§ ì‹œì‘: {len(platform_songs_dict)}ê°œ ê³¡")
                    results = strategy.crawl_platform(platform_songs_dict, self.log_writer)
                    crawling_results[platform_name] = results
                else:
                    logger.info(f"âš ï¸ {platform_name} í¬ë¡¤ë§ ëŒ€ìƒ ê³¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # 3ë‹¨ê³„: DB ì €ì¥
            logger.info("ğŸ’¾ í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
            all_song_ids = [song.id for song in active_songs]
            db_results = save_all_platforms_for_songs(
                song_ids=all_song_ids,
                genie_results=crawling_results.get('genie'),
                youtube_music_results=crawling_results.get('youtube_music'),
                youtube_results=crawling_results.get('youtube'),
                melon_results=crawling_results.get('melon')
            )
            
            # 4ë‹¨ê³„: ì‹¤íŒ¨ ì²˜ë¦¬
            logger.info("ğŸ” ì‹¤íŒ¨ ì²˜ë¦¬ ì¤‘...")
            for song in active_songs:
                FailureService.check_and_handle_failures(song.id, target_date)
            
            # ë¡œê·¸ ë¼ì´í„° ì¢…ë£Œ
            self.log_writer.end_crawling()
            
            # YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ (í›„ì²˜ë¦¬)
            logger.info("ğŸ¥ YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ ì‹œì‘ (í›„ì²˜ë¦¬)")
            try:
                update_youtube_viewcounts_for_period(
                    start_date=target_date or date.today(),
                    end_date=target_date or date.today(),
                    target_date=target_date or date.today()
                )
                logger.info("âœ… YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                # YouTube ì¡°íšŒìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨ëŠ” ì „ì²´ í¬ë¡¤ë§ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            
            # ê²°ê³¼ ìš”ì•½
            summary = self._create_summary(target_date, active_songs, crawling_results, db_results)
            
            logger.info("âœ… ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}", exc_info=True)
            return {'status': 'error', 'message': str(e)}
    
    def _create_summary(self, target_date: Optional[date], active_songs: List, crawling_results: Dict, db_results: Dict) -> Dict[str, Any]:
        """ì „ì²´ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            'status': 'success',
            'target_date': target_date or date.today(),
            'total_songs': len(active_songs),
            'crawling_results': crawling_results,
            'db_results': db_results,
            'log_summary': self.log_writer.get_summary_dict()
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_crawling_manager = None

def get_crawling_manager() -> CrawlingManager:
    """í¬ë¡¤ë§ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _crawling_manager
    if _crawling_manager is None:
        _crawling_manager = CrawlingManager()
    return _crawling_manager


# ê¸°ì¡´ í•¨ìˆ˜ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
def run_crawling(target_date=None):
    """í¬ë¡¤ë§ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    manager = get_crawling_manager()
    return manager.run_full_crawling(target_date) 