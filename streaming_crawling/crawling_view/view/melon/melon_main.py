"""
Melon í¬ë¡¤ë§ ë©”ì¸ ì‹¤í–‰ íŒŒì¼ (API ê¸°ë°˜)
"""
import logging
import time
from .melon_logic import MelonCrawler
from crawling_view.data.csv_writer import save_melon_csv
from crawling_view.data.db_writer import save_melon_to_db
import random

logger = logging.getLogger(__name__)

def run_melon_crawling(song_list, save_csv=True, save_db=True):
    """
    Melon í¬ë¡¤ë§ ì‹¤í–‰ (API ê¸°ë°˜)
    
    Args:
        song_list (list): í¬ë¡¤ë§í•  ê³¡ ë¦¬ìŠ¤íŠ¸ [{'melon_song_id': 'id', 'song_id': 'id'}, ...]
        save_csv (bool): CSV ì €ì¥ ì—¬ë¶€
        save_db (bool): DB ì €ì¥ ì—¬ë¶€
    
    Returns:
        list: í¬ë¡¤ë§ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    logger.info(f"ğŸˆ Melon í¬ë¡¤ë§ ì‹œì‘ - ì´ {len(song_list)}ê³¡")
    
    crawled_data = []
    crawler = MelonCrawler()
    
    try:
        # ê° ê³¡ì— ëŒ€í•´ í¬ë¡¤ë§ ì‹¤í–‰
        for song_info in song_list:
            melon_song_id = song_info.get('melon_song_id', '')
            song_id = song_info.get('song_id')
            
            if not melon_song_id:
                logger.warning(f"âš ï¸ melon_song_idê°€ ì—†ìŠµë‹ˆë‹¤: {song_info}")
                continue
            
            logger.debug(f"ğŸ” API í˜¸ì¶œ ì¤‘: melon_song_id={melon_song_id} (song_id={song_id})")
            
            # í¬ë¡¤ë§ ì‹¤í–‰
            result = crawler.crawl_song(melon_song_id, song_id)
            
            if result:
                crawled_data.append(result)
                logger.debug(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {result['song_title']} - {result['artist_name']} (ì¡°íšŒìˆ˜: {result['views']}, ì²­ì·¨ì: {result['listeners']})")
            else:
                logger.warning(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: melon_song_id={melon_song_id}")
            
            # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            time.sleep(random.uniform(0.5, 1.5))
        
        logger.info(f"ğŸˆ Melon í¬ë¡¤ë§ ì™„ë£Œ - ì„±ê³µ: {len(crawled_data)}ê³¡")
        
        # CSV ì €ì¥
        if save_csv and crawled_data:
            csv_path = save_melon_csv(crawled_data)
            if csv_path:
                logger.info(f"ğŸ“„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}")
        
        # DB ì €ì¥
        if save_db and crawled_data:
            saved_count = save_melon_to_db(crawled_data)
            logger.info(f"ğŸ’¾ DB ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ ë ˆì½”ë“œ")
        
        return crawled_data
        
    except Exception as e:
        logger.error(f"âŒ Melon í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
    import random
    
    test_songs = [
        {'melon_song_id': '39156202', 'song_id': 'test_1'},  # FAMOUS - ALLDAY PROJECT
        {'melon_song_id': '39156203', 'song_id': 'test_2'},  # ë‹¤ë¥¸ ê³¡
    ]
    
    results = run_melon_crawling(test_songs)
    print(f"í¬ë¡¤ë§ ê²°ê³¼: {len(results)}ê³¡") 