"""
YouTube Music í¬ë¡¤ë§ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import logging
from crawling_view.utils.driver import setup_driver
from crawling_view.data.csv_writer import save_youtube_music_csv
from crawling_view.data.db_writer import save_youtube_music_to_db
from .youtube_music_logic import YouTubeMusicCrawler

logger = logging.getLogger(__name__)

def run_youtube_music_crawling(song_list, save_csv=True, save_db=True):
    """
    YouTube Music í¬ë¡¤ë§ ì‹¤í–‰
    
    Args:
        song_list (list): í¬ë¡¤ë§í•  ê³¡ ë¦¬ìŠ¤íŠ¸ [{'song_title': 'ê³¡ëª…', 'artist_name': 'ê°€ìˆ˜ëª…', 'song_id': 'id'}, ...]
        save_csv (bool): CSV ì €ì¥ ì—¬ë¶€
        save_db (bool): DB ì €ì¥ ì—¬ë¶€
    
    Returns:
        list: í¬ë¡¤ë§ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    logger.info(f"ğŸµ YouTube Music í¬ë¡¤ë§ ì‹œì‘ - ì´ {len(song_list)}ê³¡")
    
    crawled_data = []
    
    try:
        # Chrome ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰
        with setup_driver() as driver:
            crawler = YouTubeMusicCrawler(driver)
            
            # ë¡œê·¸ì¸ ìˆ˜í–‰
            if not crawler.login():
                logger.error("âŒ YouTube Music ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return []
            
            # ê° ê³¡ì— ëŒ€í•´ í¬ë¡¤ë§ ì‹¤í–‰
            for song_info in song_list:
                song_title = song_info.get('song_title', '')
                artist_name = song_info.get('artist_name', '')
                song_id = song_info.get('song_id')
                
                logger.info(f"ğŸ” ê²€ìƒ‰ ì¤‘: {song_title} - {artist_name} (ID: {song_id})")
                
                # ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ê³¡ ì •ë³´ ì „ë‹¬
                song_data = {
                    'title_ko': song_title,
                    'title_en': song_info.get('title_en', ''),  # ì˜ë¬¸ ì œëª©ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                    'artist_ko': artist_name, 
                    'artist_en': song_info.get('artist_en', ''),  # ì˜ë¬¸ ì•„í‹°ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                    'song_id': song_id  # song_id ë°˜ë“œì‹œ í¬í•¨
                }
                
                # í¬ë¡¤ë§ ì‹¤í–‰
                result = crawler.crawl_song(song_data)
                
                if result:
                    crawled_data.append(result)
                    logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {result['song_title']} - {result['artist_name']} (ì¡°íšŒìˆ˜: {result['views']})")
                else:
                    logger.warning(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {song_title} - {artist_name}")
        
        logger.info(f"ğŸµ YouTube Music í¬ë¡¤ë§ ì™„ë£Œ - ì„±ê³µ: {len(crawled_data)}ê³¡")
        
        # CSV ì €ì¥
        if save_csv and crawled_data:
            csv_path = save_youtube_music_csv(crawled_data)
            if csv_path:
                logger.info(f"ğŸ“„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}")
        
        # DB ì €ì¥
        if save_db and crawled_data:
            saved_count = save_youtube_music_to_db(crawled_data)
            logger.info(f"ğŸ’¾ DB ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ ë ˆì½”ë“œ")
        
        return crawled_data
        
    except Exception as e:
        logger.error(f"âŒ YouTube Music í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
    test_songs = [
        {'song_title': 'Supernova', 'artist_name': 'aespa'},
        {'song_title': 'How Sweet', 'artist_name': 'NewJeans'},
    ]
    
    results = run_youtube_music_crawling(test_songs)
    print(f"í¬ë¡¤ë§ ê²°ê³¼: {len(results)}ê³¡") 